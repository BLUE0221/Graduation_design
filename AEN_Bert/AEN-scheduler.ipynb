{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import numpy as np\n",
    "data_process=imp.load_source('data_process','../data_process.py')\n",
    "from data_process import get_xml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents,train_contexts,train_labels=get_xml_data('../SMP2019/SMP2019_ECISA_Train.xml')\n",
    "validation_sents,validation_contexts,validation_labels=get_xml_data('../SMP2019/SMP2019_ECISA_Dev.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel,BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_name='hfl/chinese-bert-wwm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained(bert_name, return_dict=False)\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bertTensor(text_list,MAX_LEN = 128):\n",
    "    words_idx = []\n",
    "    for sent in text_list:\n",
    "        encoded_sent = tokenizer.encode(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = MAX_LEN,          # Truncate all sentences.\n",
    "                            #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "        \n",
    "        words_idx.append(encoded_sent)\n",
    "    \n",
    "    words_idx=pad_sequences(words_idx, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "    words_masks=[]\n",
    "    for sent in words_idx:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        words_masks.append(att_mask)\n",
    "        \n",
    "    return torch.tensor(words_idx),torch.tensor(words_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "train_sents,train_sents_masks=get_bertTensor(train_sents)\n",
    "train_contexts,train_contexts_masks=get_bertTensor(train_contexts,MAX_LEN=256)\n",
    "train_labels=torch.tensor(train_labels)\n",
    "\n",
    "validation_sents,validation_sents_masks=get_bertTensor(validation_sents)\n",
    "validation_contexts,validation_contexts_masks=get_bertTensor(validation_contexts,MAX_LEN=256)\n",
    "validation_labels=torch.tensor(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "train_data = TensorDataset(train_sents,train_sents_masks,train_contexts,train_contexts_masks,train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_sents,validation_sents_masks,validation_contexts,\n",
    "                                validation_contexts_masks,validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 AEN_Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.dynamic_rnn import DynamicLSTM\n",
    "from layers.squeeze_embedding import SqueezeEmbedding\n",
    "from layers.attention import Attention, NoQueryAttention\n",
    "from layers.point_wise_feed_forward import PositionwiseFeedForward\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEN_BERT(nn.Module):\n",
    "    def __init__(self,bert):\n",
    "        super(AEN_BERT, self).__init__()\n",
    "\n",
    "        dropout=0.1\n",
    "        bert_dim=768    \n",
    "        hidden_dim=300\n",
    "        polarities_dim=3\n",
    "        \n",
    "        self.drop_path_prob=0.0\n",
    "        self.bert=bert\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attn_k = Attention(bert_dim, out_dim=hidden_dim, n_head=8, score_function='mlp', dropout=dropout)\n",
    "        self.attn_q = Attention(bert_dim, out_dim=hidden_dim, n_head=8, score_function='mlp', dropout=dropout)\n",
    "        self.ffn_c = PositionwiseFeedForward(hidden_dim, dropout=dropout)\n",
    "        self.ffn_t = PositionwiseFeedForward(hidden_dim, dropout=dropout)\n",
    "\n",
    "        self.attn_s1 = Attention(hidden_dim, n_head=8, score_function='mlp', dropout=dropout)\n",
    "        self.dense = nn.Linear(hidden_dim*3, polarities_dim)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "#         context, target = inputs[0], inputs[1]\n",
    "        context_len=128\n",
    "        target_len=128\n",
    "        \n",
    "        target,_=bert(a_input_ids, token_type_ids=None, attention_mask=a_input_mask,)\n",
    "        context,_=bert(b_input_ids, token_type_ids=None, attention_mask=b_input_mask,)\n",
    "#         context_len = torch.sum(context != 0, dim=-1)\n",
    "#         target_len = torch.sum(target != 0, dim=-1)\n",
    "#         context = self.squeeze_embedding(context, context_len)\n",
    "#         context, _ = self.bert(context)\n",
    "        context = self.dropout(context)\n",
    "        target = self.dropout(target)\n",
    "\n",
    "        hc, _ = self.attn_k(context, context)\n",
    "        hc = self.ffn_c(hc)\n",
    "#         ht, _ = self.attn_q(context, target)\n",
    "        ht, _ = self.attn_q(target, target)\n",
    "        ht = self.ffn_t(ht)\n",
    "\n",
    "        s1, _ = self.attn_s1(hc, ht)\n",
    "\n",
    "        hc_mean = torch.div(torch.sum(hc, dim=1), context_len)\n",
    "        ht_mean = torch.div(torch.sum(ht, dim=1), target_len)\n",
    "        s1_mean = torch.div(torch.sum(s1, dim=1), context_len)\n",
    "\n",
    "        x = torch.cat((hc_mean, s1_mean, ht_mean), dim=-1)\n",
    "        out=self.dense(x)\n",
    "#         out = torch.argmax(self.softmax(self.dense(x)),dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "# model = torch.nn.DataParallel(model, device_ids=[0,2,3]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():     \n",
    "    device = torch.device(\"cuda:0\")#select gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert.cuda()\n",
    "model=AEN_BERT(bert)\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n",
    "epochs=4\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot,acc_plot=[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuke/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of  2,463.    Elapsed: 0:00:15.\n",
      "loss: 0.9832, acc: 0.5528\n",
      "  Batch    80  of  2,463.    Elapsed: 0:00:28.\n",
      "loss: 0.8093, acc: 0.6708\n",
      "  Batch   120  of  2,463.    Elapsed: 0:00:41.\n",
      "loss: 0.7491, acc: 0.6958\n",
      "  Batch   160  of  2,463.    Elapsed: 0:00:53.\n",
      "loss: 0.6739, acc: 0.7167\n",
      "  Batch   200  of  2,463.    Elapsed: 0:01:05.\n",
      "loss: 0.6870, acc: 0.6875\n",
      "  Batch   240  of  2,463.    Elapsed: 0:01:18.\n",
      "loss: 0.6674, acc: 0.7042\n",
      "  Batch   280  of  2,463.    Elapsed: 0:01:30.\n",
      "loss: 0.6349, acc: 0.7500\n",
      "  Batch   320  of  2,463.    Elapsed: 0:01:42.\n",
      "loss: 0.6394, acc: 0.7417\n",
      "  Batch   360  of  2,463.    Elapsed: 0:01:54.\n",
      "loss: 0.6554, acc: 0.7250\n",
      "  Batch   400  of  2,463.    Elapsed: 0:02:06.\n",
      "loss: 0.5494, acc: 0.7750\n",
      "  Batch   440  of  2,463.    Elapsed: 0:02:19.\n",
      "loss: 0.5945, acc: 0.7625\n",
      "  Batch   480  of  2,463.    Elapsed: 0:02:31.\n",
      "loss: 0.5681, acc: 0.7667\n",
      "  Batch   520  of  2,463.    Elapsed: 0:02:43.\n",
      "loss: 0.5078, acc: 0.8000\n",
      "  Batch   560  of  2,463.    Elapsed: 0:02:56.\n",
      "loss: 0.5363, acc: 0.7750\n",
      "  Batch   600  of  2,463.    Elapsed: 0:03:08.\n",
      "loss: 0.5317, acc: 0.7708\n",
      "  Batch   640  of  2,463.    Elapsed: 0:03:20.\n",
      "loss: 0.6018, acc: 0.7625\n",
      "  Batch   680  of  2,463.    Elapsed: 0:03:32.\n",
      "loss: 0.5746, acc: 0.7792\n",
      "  Batch   720  of  2,463.    Elapsed: 0:03:44.\n",
      "loss: 0.4626, acc: 0.8333\n",
      "  Batch   760  of  2,463.    Elapsed: 0:03:57.\n",
      "loss: 0.4717, acc: 0.8292\n",
      "  Batch   800  of  2,463.    Elapsed: 0:04:09.\n",
      "loss: 0.5464, acc: 0.7708\n",
      "  Batch   840  of  2,463.    Elapsed: 0:04:21.\n",
      "loss: 0.4680, acc: 0.8125\n",
      "  Batch   880  of  2,463.    Elapsed: 0:04:33.\n",
      "loss: 0.5728, acc: 0.7708\n",
      "  Batch   920  of  2,463.    Elapsed: 0:04:46.\n",
      "loss: 0.4769, acc: 0.8250\n",
      "  Batch   960  of  2,463.    Elapsed: 0:04:59.\n",
      "loss: 0.5057, acc: 0.7958\n",
      "  Batch 1,000  of  2,463.    Elapsed: 0:05:11.\n",
      "loss: 0.5355, acc: 0.7917\n",
      "  Batch 1,040  of  2,463.    Elapsed: 0:05:23.\n",
      "loss: 0.4749, acc: 0.8208\n",
      "  Batch 1,080  of  2,463.    Elapsed: 0:05:36.\n",
      "loss: 0.5395, acc: 0.7833\n",
      "  Batch 1,120  of  2,463.    Elapsed: 0:05:48.\n",
      "loss: 0.4432, acc: 0.8333\n",
      "  Batch 1,160  of  2,463.    Elapsed: 0:06:00.\n",
      "loss: 0.4464, acc: 0.8333\n",
      "  Batch 1,200  of  2,463.    Elapsed: 0:06:13.\n",
      "loss: 0.5063, acc: 0.7958\n",
      "  Batch 1,240  of  2,463.    Elapsed: 0:06:25.\n",
      "loss: 0.4771, acc: 0.8250\n",
      "  Batch 1,280  of  2,463.    Elapsed: 0:06:37.\n",
      "loss: 0.4843, acc: 0.8208\n",
      "  Batch 1,320  of  2,463.    Elapsed: 0:06:49.\n",
      "loss: 0.5188, acc: 0.7833\n",
      "  Batch 1,360  of  2,463.    Elapsed: 0:07:02.\n",
      "loss: 0.4435, acc: 0.8458\n",
      "  Batch 1,400  of  2,463.    Elapsed: 0:07:14.\n",
      "loss: 0.4131, acc: 0.8417\n",
      "  Batch 1,440  of  2,463.    Elapsed: 0:07:27.\n",
      "loss: 0.3681, acc: 0.8375\n",
      "  Batch 1,480  of  2,463.    Elapsed: 0:07:41.\n",
      "loss: 0.4766, acc: 0.8167\n",
      "  Batch 1,520  of  2,463.    Elapsed: 0:07:54.\n",
      "loss: 0.4911, acc: 0.7875\n",
      "  Batch 1,560  of  2,463.    Elapsed: 0:08:06.\n",
      "loss: 0.4827, acc: 0.7792\n",
      "  Batch 1,600  of  2,463.    Elapsed: 0:08:18.\n",
      "loss: 0.4719, acc: 0.8125\n",
      "  Batch 1,640  of  2,463.    Elapsed: 0:08:30.\n",
      "loss: 0.4795, acc: 0.7833\n",
      "  Batch 1,680  of  2,463.    Elapsed: 0:08:42.\n",
      "loss: 0.4439, acc: 0.8083\n",
      "  Batch 1,720  of  2,463.    Elapsed: 0:08:55.\n",
      "loss: 0.4597, acc: 0.8292\n",
      "  Batch 1,760  of  2,463.    Elapsed: 0:09:07.\n",
      "loss: 0.4422, acc: 0.8167\n",
      "  Batch 1,800  of  2,463.    Elapsed: 0:09:19.\n",
      "loss: 0.5263, acc: 0.7958\n",
      "  Batch 1,840  of  2,463.    Elapsed: 0:09:32.\n",
      "loss: 0.4607, acc: 0.8333\n",
      "  Batch 1,880  of  2,463.    Elapsed: 0:09:45.\n",
      "loss: 0.5157, acc: 0.7917\n",
      "  Batch 1,920  of  2,463.    Elapsed: 0:09:57.\n",
      "loss: 0.4947, acc: 0.7958\n",
      "  Batch 1,960  of  2,463.    Elapsed: 0:10:10.\n",
      "loss: 0.5307, acc: 0.7875\n",
      "  Batch 2,000  of  2,463.    Elapsed: 0:10:22.\n",
      "loss: 0.5107, acc: 0.7792\n",
      "  Batch 2,040  of  2,463.    Elapsed: 0:10:34.\n",
      "loss: 0.4593, acc: 0.8042\n",
      "  Batch 2,080  of  2,463.    Elapsed: 0:10:47.\n",
      "loss: 0.4636, acc: 0.8125\n",
      "  Batch 2,120  of  2,463.    Elapsed: 0:10:59.\n",
      "loss: 0.4772, acc: 0.8125\n",
      "  Batch 2,160  of  2,463.    Elapsed: 0:11:12.\n",
      "loss: 0.4330, acc: 0.8250\n",
      "  Batch 2,200  of  2,463.    Elapsed: 0:11:24.\n",
      "loss: 0.3645, acc: 0.8458\n",
      "  Batch 2,240  of  2,463.    Elapsed: 0:11:36.\n",
      "loss: 0.4605, acc: 0.8208\n",
      "  Batch 2,280  of  2,463.    Elapsed: 0:11:49.\n",
      "loss: 0.4491, acc: 0.8083\n",
      "  Batch 2,320  of  2,463.    Elapsed: 0:12:01.\n",
      "loss: 0.4890, acc: 0.8167\n",
      "  Batch 2,360  of  2,463.    Elapsed: 0:12:13.\n",
      "loss: 0.4450, acc: 0.8167\n",
      "  Batch 2,400  of  2,463.    Elapsed: 0:12:25.\n",
      "loss: 0.3950, acc: 0.8750\n",
      "  Batch 2,440  of  2,463.    Elapsed: 0:12:37.\n",
      "loss: 0.4235, acc: 0.8167\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90      2553\n",
      "           1       0.83      0.62      0.71      1232\n",
      "           2       0.77      0.87      0.81      1358\n",
      "\n",
      "    accuracy                           0.84      5143\n",
      "   macro avg       0.82      0.80      0.81      5143\n",
      "weighted avg       0.84      0.84      0.83      5143\n",
      "\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  2,463.    Elapsed: 0:00:14.\n",
      "loss: 0.3495, acc: 0.8699\n",
      "  Batch    80  of  2,463.    Elapsed: 0:00:28.\n",
      "loss: 0.3221, acc: 0.8875\n",
      "  Batch   120  of  2,463.    Elapsed: 0:00:43.\n",
      "loss: 0.2390, acc: 0.9125\n",
      "  Batch   160  of  2,463.    Elapsed: 0:00:56.\n",
      "loss: 0.3485, acc: 0.8625\n",
      "  Batch   200  of  2,463.    Elapsed: 0:01:09.\n",
      "loss: 0.3279, acc: 0.8667\n",
      "  Batch   240  of  2,463.    Elapsed: 0:01:22.\n",
      "loss: 0.2695, acc: 0.8958\n",
      "  Batch   280  of  2,463.    Elapsed: 0:01:34.\n",
      "loss: 0.3321, acc: 0.8583\n",
      "  Batch   320  of  2,463.    Elapsed: 0:01:46.\n",
      "loss: 0.3363, acc: 0.8875\n",
      "  Batch   360  of  2,463.    Elapsed: 0:01:59.\n",
      "loss: 0.3987, acc: 0.8417\n",
      "  Batch   400  of  2,463.    Elapsed: 0:02:11.\n",
      "loss: 0.3045, acc: 0.8792\n",
      "  Batch   440  of  2,463.    Elapsed: 0:02:23.\n",
      "loss: 0.3664, acc: 0.8542\n",
      "  Batch   480  of  2,463.    Elapsed: 0:02:35.\n",
      "loss: 0.2510, acc: 0.9042\n",
      "  Batch   520  of  2,463.    Elapsed: 0:02:47.\n",
      "loss: 0.3028, acc: 0.8667\n",
      "  Batch   560  of  2,463.    Elapsed: 0:03:00.\n",
      "loss: 0.3198, acc: 0.8750\n",
      "  Batch   600  of  2,463.    Elapsed: 0:03:12.\n",
      "loss: 0.2937, acc: 0.8875\n",
      "  Batch   640  of  2,463.    Elapsed: 0:03:24.\n",
      "loss: 0.2761, acc: 0.8792\n",
      "  Batch   680  of  2,463.    Elapsed: 0:03:36.\n",
      "loss: 0.2690, acc: 0.9167\n",
      "  Batch   720  of  2,463.    Elapsed: 0:03:48.\n",
      "loss: 0.2886, acc: 0.8750\n",
      "  Batch   760  of  2,463.    Elapsed: 0:04:01.\n",
      "loss: 0.2721, acc: 0.8958\n",
      "  Batch   800  of  2,463.    Elapsed: 0:04:13.\n",
      "loss: 0.3597, acc: 0.8792\n",
      "  Batch   840  of  2,463.    Elapsed: 0:04:25.\n",
      "loss: 0.2559, acc: 0.9250\n",
      "  Batch   880  of  2,463.    Elapsed: 0:04:38.\n",
      "loss: 0.3321, acc: 0.8583\n",
      "  Batch   920  of  2,463.    Elapsed: 0:04:50.\n",
      "loss: 0.3205, acc: 0.8667\n",
      "  Batch   960  of  2,463.    Elapsed: 0:05:02.\n",
      "loss: 0.3024, acc: 0.8875\n",
      "  Batch 1,000  of  2,463.    Elapsed: 0:05:14.\n",
      "loss: 0.2849, acc: 0.8958\n",
      "  Batch 1,040  of  2,463.    Elapsed: 0:05:27.\n",
      "loss: 0.2670, acc: 0.9000\n",
      "  Batch 1,080  of  2,463.    Elapsed: 0:05:39.\n",
      "loss: 0.3391, acc: 0.8667\n",
      "  Batch 1,120  of  2,463.    Elapsed: 0:05:52.\n",
      "loss: 0.2848, acc: 0.9083\n",
      "  Batch 1,160  of  2,463.    Elapsed: 0:06:05.\n",
      "loss: 0.3052, acc: 0.8667\n",
      "  Batch 1,200  of  2,463.    Elapsed: 0:06:17.\n",
      "loss: 0.2727, acc: 0.8875\n",
      "  Batch 1,240  of  2,463.    Elapsed: 0:06:29.\n",
      "loss: 0.3546, acc: 0.8750\n",
      "  Batch 1,280  of  2,463.    Elapsed: 0:06:41.\n",
      "loss: 0.2406, acc: 0.9042\n",
      "  Batch 1,320  of  2,463.    Elapsed: 0:06:54.\n",
      "loss: 0.2760, acc: 0.9042\n",
      "  Batch 1,360  of  2,463.    Elapsed: 0:07:06.\n",
      "loss: 0.2611, acc: 0.9083\n",
      "  Batch 1,400  of  2,463.    Elapsed: 0:07:18.\n",
      "loss: 0.4432, acc: 0.8208\n",
      "  Batch 1,440  of  2,463.    Elapsed: 0:07:31.\n",
      "loss: 0.2628, acc: 0.9125\n",
      "  Batch 1,480  of  2,463.    Elapsed: 0:07:43.\n",
      "loss: 0.2683, acc: 0.8875\n",
      "  Batch 1,520  of  2,463.    Elapsed: 0:07:56.\n",
      "loss: 0.3325, acc: 0.8667\n",
      "  Batch 1,560  of  2,463.    Elapsed: 0:08:09.\n",
      "loss: 0.3053, acc: 0.8917\n",
      "  Batch 1,600  of  2,463.    Elapsed: 0:08:22.\n",
      "loss: 0.2772, acc: 0.8875\n",
      "  Batch 1,640  of  2,463.    Elapsed: 0:08:34.\n",
      "loss: 0.3203, acc: 0.8875\n",
      "  Batch 1,680  of  2,463.    Elapsed: 0:08:46.\n",
      "loss: 0.2529, acc: 0.8958\n",
      "  Batch 1,720  of  2,463.    Elapsed: 0:08:59.\n",
      "loss: 0.2718, acc: 0.9000\n",
      "  Batch 1,760  of  2,463.    Elapsed: 0:09:11.\n",
      "loss: 0.2494, acc: 0.8958\n",
      "  Batch 1,800  of  2,463.    Elapsed: 0:09:23.\n",
      "loss: 0.3145, acc: 0.8708\n",
      "  Batch 1,840  of  2,463.    Elapsed: 0:09:35.\n",
      "loss: 0.2085, acc: 0.9125\n",
      "  Batch 1,880  of  2,463.    Elapsed: 0:09:48.\n",
      "loss: 0.3291, acc: 0.8583\n",
      "  Batch 1,920  of  2,463.    Elapsed: 0:10:00.\n",
      "loss: 0.3518, acc: 0.8708\n",
      "  Batch 1,960  of  2,463.    Elapsed: 0:10:13.\n",
      "loss: 0.2700, acc: 0.8833\n",
      "  Batch 2,000  of  2,463.    Elapsed: 0:10:25.\n",
      "loss: 0.3393, acc: 0.8833\n",
      "  Batch 2,040  of  2,463.    Elapsed: 0:10:38.\n",
      "loss: 0.2329, acc: 0.9292\n",
      "  Batch 2,080  of  2,463.    Elapsed: 0:10:51.\n",
      "loss: 0.2201, acc: 0.9125\n",
      "  Batch 2,120  of  2,463.    Elapsed: 0:11:03.\n",
      "loss: 0.2467, acc: 0.9208\n",
      "  Batch 2,160  of  2,463.    Elapsed: 0:11:15.\n",
      "loss: 0.2941, acc: 0.8958\n",
      "  Batch 2,200  of  2,463.    Elapsed: 0:11:28.\n",
      "loss: 0.3169, acc: 0.8750\n",
      "  Batch 2,240  of  2,463.    Elapsed: 0:11:40.\n",
      "loss: 0.2542, acc: 0.8958\n",
      "  Batch 2,280  of  2,463.    Elapsed: 0:11:52.\n",
      "loss: 0.2961, acc: 0.8792\n",
      "  Batch 2,320  of  2,463.    Elapsed: 0:12:04.\n",
      "loss: 0.2672, acc: 0.9083\n",
      "  Batch 2,360  of  2,463.    Elapsed: 0:12:17.\n",
      "loss: 0.3930, acc: 0.8458\n",
      "  Batch 2,400  of  2,463.    Elapsed: 0:12:29.\n",
      "loss: 0.3302, acc: 0.8583\n",
      "  Batch 2,440  of  2,463.    Elapsed: 0:12:41.\n",
      "loss: 0.2512, acc: 0.9125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      2553\n",
      "           1       0.77      0.70      0.73      1232\n",
      "           2       0.80      0.84      0.82      1358\n",
      "\n",
      "    accuracy                           0.84      5143\n",
      "   macro avg       0.82      0.82      0.82      5143\n",
      "weighted avg       0.84      0.84      0.84      5143\n",
      "\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  2,463.    Elapsed: 0:00:13.\n",
      "loss: 0.1506, acc: 0.9472\n",
      "  Batch    80  of  2,463.    Elapsed: 0:00:25.\n",
      "loss: 0.1420, acc: 0.9583\n",
      "  Batch   120  of  2,463.    Elapsed: 0:00:39.\n",
      "loss: 0.1247, acc: 0.9542\n",
      "  Batch   160  of  2,463.    Elapsed: 0:00:52.\n",
      "loss: 0.1458, acc: 0.9500\n",
      "  Batch   200  of  2,463.    Elapsed: 0:01:07.\n",
      "loss: 0.1920, acc: 0.9542\n",
      "  Batch   240  of  2,463.    Elapsed: 0:01:20.\n",
      "loss: 0.1331, acc: 0.9458\n",
      "  Batch   280  of  2,463.    Elapsed: 0:01:33.\n",
      "loss: 0.1411, acc: 0.9625\n",
      "  Batch   320  of  2,463.    Elapsed: 0:01:46.\n",
      "loss: 0.2319, acc: 0.9042\n",
      "  Batch   360  of  2,463.    Elapsed: 0:01:58.\n",
      "loss: 0.1219, acc: 0.9500\n",
      "  Batch   400  of  2,463.    Elapsed: 0:02:11.\n",
      "loss: 0.1566, acc: 0.9625\n",
      "  Batch   440  of  2,463.    Elapsed: 0:02:23.\n",
      "loss: 0.1645, acc: 0.9333\n",
      "  Batch   480  of  2,463.    Elapsed: 0:02:36.\n",
      "loss: 0.1431, acc: 0.9542\n",
      "  Batch   520  of  2,463.    Elapsed: 0:02:48.\n",
      "loss: 0.1127, acc: 0.9667\n",
      "  Batch   560  of  2,463.    Elapsed: 0:03:00.\n",
      "loss: 0.1609, acc: 0.9458\n",
      "  Batch   600  of  2,463.    Elapsed: 0:03:13.\n",
      "loss: 0.1472, acc: 0.9625\n",
      "  Batch   640  of  2,463.    Elapsed: 0:03:25.\n",
      "loss: 0.1300, acc: 0.9542\n",
      "  Batch   680  of  2,463.    Elapsed: 0:03:37.\n",
      "loss: 0.1750, acc: 0.9417\n",
      "  Batch   720  of  2,463.    Elapsed: 0:03:50.\n",
      "loss: 0.1488, acc: 0.9583\n",
      "  Batch   760  of  2,463.    Elapsed: 0:04:02.\n",
      "loss: 0.1118, acc: 0.9583\n",
      "  Batch   800  of  2,463.    Elapsed: 0:04:14.\n",
      "loss: 0.1161, acc: 0.9625\n",
      "  Batch   840  of  2,463.    Elapsed: 0:04:26.\n",
      "loss: 0.1255, acc: 0.9667\n",
      "  Batch   880  of  2,463.    Elapsed: 0:04:38.\n",
      "loss: 0.1240, acc: 0.9500\n",
      "  Batch   920  of  2,463.    Elapsed: 0:04:51.\n",
      "loss: 0.1409, acc: 0.9375\n",
      "  Batch   960  of  2,463.    Elapsed: 0:05:03.\n",
      "loss: 0.1014, acc: 0.9708\n",
      "  Batch 1,000  of  2,463.    Elapsed: 0:05:15.\n",
      "loss: 0.1539, acc: 0.9500\n",
      "  Batch 1,040  of  2,463.    Elapsed: 0:05:28.\n",
      "loss: 0.1567, acc: 0.9542\n",
      "  Batch 1,080  of  2,463.    Elapsed: 0:05:40.\n",
      "loss: 0.1649, acc: 0.9500\n",
      "  Batch 1,120  of  2,463.    Elapsed: 0:05:52.\n",
      "loss: 0.1864, acc: 0.9333\n",
      "  Batch 1,160  of  2,463.    Elapsed: 0:06:04.\n",
      "loss: 0.1820, acc: 0.9458\n",
      "  Batch 1,200  of  2,463.    Elapsed: 0:06:17.\n",
      "loss: 0.1662, acc: 0.9417\n",
      "  Batch 1,240  of  2,463.    Elapsed: 0:06:30.\n",
      "loss: 0.1684, acc: 0.9417\n",
      "  Batch 1,280  of  2,463.    Elapsed: 0:06:42.\n",
      "loss: 0.1652, acc: 0.9417\n",
      "  Batch 1,320  of  2,463.    Elapsed: 0:06:55.\n",
      "loss: 0.1527, acc: 0.9583\n",
      "  Batch 1,360  of  2,463.    Elapsed: 0:07:07.\n",
      "loss: 0.1682, acc: 0.9500\n",
      "  Batch 1,400  of  2,463.    Elapsed: 0:07:19.\n",
      "loss: 0.1154, acc: 0.9375\n",
      "  Batch 1,440  of  2,463.    Elapsed: 0:07:31.\n",
      "loss: 0.1245, acc: 0.9458\n",
      "  Batch 1,480  of  2,463.    Elapsed: 0:07:43.\n",
      "loss: 0.1510, acc: 0.9417\n",
      "  Batch 1,520  of  2,463.    Elapsed: 0:07:56.\n",
      "loss: 0.1409, acc: 0.9542\n",
      "  Batch 1,560  of  2,463.    Elapsed: 0:08:08.\n",
      "loss: 0.1077, acc: 0.9583\n",
      "  Batch 1,600  of  2,463.    Elapsed: 0:08:20.\n",
      "loss: 0.1522, acc: 0.9542\n",
      "  Batch 1,640  of  2,463.    Elapsed: 0:08:33.\n",
      "loss: 0.1669, acc: 0.9333\n",
      "  Batch 1,680  of  2,463.    Elapsed: 0:08:46.\n",
      "loss: 0.1205, acc: 0.9542\n",
      "  Batch 1,720  of  2,463.    Elapsed: 0:08:59.\n",
      "loss: 0.1392, acc: 0.9333\n",
      "  Batch 1,760  of  2,463.    Elapsed: 0:09:12.\n",
      "loss: 0.1694, acc: 0.9250\n",
      "  Batch 1,800  of  2,463.    Elapsed: 0:09:25.\n",
      "loss: 0.1274, acc: 0.9500\n",
      "  Batch 1,840  of  2,463.    Elapsed: 0:09:37.\n",
      "loss: 0.1026, acc: 0.9542\n",
      "  Batch 1,880  of  2,463.    Elapsed: 0:09:49.\n",
      "loss: 0.1052, acc: 0.9583\n",
      "  Batch 1,920  of  2,463.    Elapsed: 0:10:01.\n",
      "loss: 0.1119, acc: 0.9750\n",
      "  Batch 1,960  of  2,463.    Elapsed: 0:10:14.\n",
      "loss: 0.0989, acc: 0.9625\n",
      "  Batch 2,000  of  2,463.    Elapsed: 0:10:26.\n",
      "loss: 0.1055, acc: 0.9542\n",
      "  Batch 2,040  of  2,463.    Elapsed: 0:10:38.\n",
      "loss: 0.1163, acc: 0.9667\n",
      "  Batch 2,080  of  2,463.    Elapsed: 0:10:50.\n",
      "loss: 0.1285, acc: 0.9583\n",
      "  Batch 2,120  of  2,463.    Elapsed: 0:11:02.\n",
      "loss: 0.1299, acc: 0.9542\n",
      "  Batch 2,160  of  2,463.    Elapsed: 0:11:15.\n",
      "loss: 0.1261, acc: 0.9500\n",
      "  Batch 2,200  of  2,463.    Elapsed: 0:11:29.\n",
      "loss: 0.1679, acc: 0.9458\n",
      "  Batch 2,240  of  2,463.    Elapsed: 0:11:41.\n",
      "loss: 0.0644, acc: 0.9750\n",
      "  Batch 2,280  of  2,463.    Elapsed: 0:11:53.\n",
      "loss: 0.1177, acc: 0.9542\n",
      "  Batch 2,320  of  2,463.    Elapsed: 0:12:06.\n",
      "loss: 0.1510, acc: 0.9292\n",
      "  Batch 2,360  of  2,463.    Elapsed: 0:12:18.\n",
      "loss: 0.1118, acc: 0.9542\n",
      "  Batch 2,400  of  2,463.    Elapsed: 0:12:30.\n",
      "loss: 0.1464, acc: 0.9417\n",
      "  Batch 2,440  of  2,463.    Elapsed: 0:12:42.\n",
      "loss: 0.1580, acc: 0.9458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      2553\n",
      "           1       0.78      0.69      0.73      1232\n",
      "           2       0.80      0.84      0.82      1358\n",
      "\n",
      "    accuracy                           0.84      5143\n",
      "   macro avg       0.82      0.81      0.81      5143\n",
      "weighted avg       0.83      0.84      0.83      5143\n",
      "\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  2,463.    Elapsed: 0:00:13.\n",
      "loss: 0.0575, acc: 0.9837\n",
      "  Batch    80  of  2,463.    Elapsed: 0:00:25.\n",
      "loss: 0.0519, acc: 0.9875\n",
      "  Batch   120  of  2,463.    Elapsed: 0:00:37.\n",
      "loss: 0.0491, acc: 0.9875\n",
      "  Batch   160  of  2,463.    Elapsed: 0:00:49.\n",
      "loss: 0.0326, acc: 0.9917\n",
      "  Batch   200  of  2,463.    Elapsed: 0:01:01.\n",
      "loss: 0.0452, acc: 0.9875\n",
      "  Batch   240  of  2,463.    Elapsed: 0:01:14.\n",
      "loss: 0.0495, acc: 0.9875\n",
      "  Batch   280  of  2,463.    Elapsed: 0:01:27.\n",
      "loss: 0.0513, acc: 0.9792\n",
      "  Batch   320  of  2,463.    Elapsed: 0:01:41.\n",
      "loss: 0.1131, acc: 0.9583\n",
      "  Batch   360  of  2,463.    Elapsed: 0:01:55.\n",
      "loss: 0.0588, acc: 0.9875\n",
      "  Batch   400  of  2,463.    Elapsed: 0:02:09.\n",
      "loss: 0.0621, acc: 0.9750\n",
      "  Batch   440  of  2,463.    Elapsed: 0:02:22.\n",
      "loss: 0.0542, acc: 0.9792\n",
      "  Batch   480  of  2,463.    Elapsed: 0:02:36.\n",
      "loss: 0.0336, acc: 0.9875\n",
      "  Batch   520  of  2,463.    Elapsed: 0:02:49.\n",
      "loss: 0.0453, acc: 0.9917\n",
      "  Batch   560  of  2,463.    Elapsed: 0:03:01.\n",
      "loss: 0.0495, acc: 0.9917\n",
      "  Batch   600  of  2,463.    Elapsed: 0:03:13.\n",
      "loss: 0.0445, acc: 0.9833\n",
      "  Batch   640  of  2,463.    Elapsed: 0:03:25.\n",
      "loss: 0.0576, acc: 0.9917\n",
      "  Batch   680  of  2,463.    Elapsed: 0:03:38.\n",
      "loss: 0.0347, acc: 0.9875\n",
      "  Batch   720  of  2,463.    Elapsed: 0:03:50.\n",
      "loss: 0.0377, acc: 0.9875\n",
      "  Batch   760  of  2,463.    Elapsed: 0:04:03.\n",
      "loss: 0.0299, acc: 0.9958\n",
      "  Batch   800  of  2,463.    Elapsed: 0:04:15.\n",
      "loss: 0.1286, acc: 0.9667\n",
      "  Batch   840  of  2,463.    Elapsed: 0:04:27.\n",
      "loss: 0.0426, acc: 0.9917\n",
      "  Batch   880  of  2,463.    Elapsed: 0:04:40.\n",
      "loss: 0.0548, acc: 0.9833\n",
      "  Batch   920  of  2,463.    Elapsed: 0:04:52.\n",
      "loss: 0.0502, acc: 0.9833\n",
      "  Batch   960  of  2,463.    Elapsed: 0:05:04.\n",
      "loss: 0.0252, acc: 0.9917\n",
      "  Batch 1,000  of  2,463.    Elapsed: 0:05:17.\n",
      "loss: 0.1200, acc: 0.9708\n",
      "  Batch 1,040  of  2,463.    Elapsed: 0:05:29.\n",
      "loss: 0.0510, acc: 0.9792\n",
      "  Batch 1,080  of  2,463.    Elapsed: 0:05:41.\n",
      "loss: 0.0633, acc: 0.9708\n",
      "  Batch 1,120  of  2,463.    Elapsed: 0:05:53.\n",
      "loss: 0.0710, acc: 0.9750\n",
      "  Batch 1,160  of  2,463.    Elapsed: 0:06:06.\n",
      "loss: 0.0450, acc: 0.9792\n",
      "  Batch 1,200  of  2,463.    Elapsed: 0:06:18.\n",
      "loss: 0.0482, acc: 0.9833\n",
      "  Batch 1,240  of  2,463.    Elapsed: 0:06:30.\n",
      "loss: 0.0375, acc: 0.9833\n",
      "  Batch 1,280  of  2,463.    Elapsed: 0:06:42.\n",
      "loss: 0.1292, acc: 0.9542\n",
      "  Batch 1,320  of  2,463.    Elapsed: 0:06:54.\n",
      "loss: 0.0469, acc: 0.9792\n",
      "  Batch 1,360  of  2,463.    Elapsed: 0:07:07.\n",
      "loss: 0.0775, acc: 0.9750\n",
      "  Batch 1,400  of  2,463.    Elapsed: 0:07:20.\n",
      "loss: 0.0728, acc: 0.9750\n",
      "  Batch 1,440  of  2,463.    Elapsed: 0:07:33.\n",
      "loss: 0.0725, acc: 0.9708\n",
      "  Batch 1,480  of  2,463.    Elapsed: 0:07:45.\n",
      "loss: 0.0494, acc: 0.9792\n",
      "  Batch 1,520  of  2,463.    Elapsed: 0:07:57.\n",
      "loss: 0.0586, acc: 0.9792\n",
      "  Batch 1,560  of  2,463.    Elapsed: 0:08:09.\n",
      "loss: 0.0556, acc: 0.9792\n",
      "  Batch 1,600  of  2,463.    Elapsed: 0:08:22.\n",
      "loss: 0.0327, acc: 0.9917\n",
      "  Batch 1,640  of  2,463.    Elapsed: 0:08:34.\n",
      "loss: 0.0384, acc: 0.9833\n",
      "  Batch 1,680  of  2,463.    Elapsed: 0:08:46.\n",
      "loss: 0.0582, acc: 0.9792\n",
      "  Batch 1,720  of  2,463.    Elapsed: 0:08:59.\n",
      "loss: 0.0285, acc: 0.9875\n",
      "  Batch 1,760  of  2,463.    Elapsed: 0:09:11.\n",
      "loss: 0.0343, acc: 0.9917\n",
      "  Batch 1,800  of  2,463.    Elapsed: 0:09:23.\n",
      "loss: 0.0287, acc: 0.9875\n",
      "  Batch 1,840  of  2,463.    Elapsed: 0:09:37.\n",
      "loss: 0.0750, acc: 0.9708\n",
      "  Batch 1,880  of  2,463.    Elapsed: 0:09:50.\n",
      "loss: 0.0357, acc: 0.9875\n",
      "  Batch 1,920  of  2,463.    Elapsed: 0:10:03.\n",
      "loss: 0.0826, acc: 0.9750\n",
      "  Batch 1,960  of  2,463.    Elapsed: 0:10:15.\n",
      "loss: 0.0383, acc: 0.9833\n",
      "  Batch 2,000  of  2,463.    Elapsed: 0:10:27.\n",
      "loss: 0.0985, acc: 0.9708\n",
      "  Batch 2,040  of  2,463.    Elapsed: 0:10:40.\n",
      "loss: 0.0550, acc: 0.9833\n",
      "  Batch 2,080  of  2,463.    Elapsed: 0:10:52.\n",
      "loss: 0.0624, acc: 0.9792\n",
      "  Batch 2,120  of  2,463.    Elapsed: 0:11:04.\n",
      "loss: 0.0386, acc: 0.9917\n",
      "  Batch 2,160  of  2,463.    Elapsed: 0:11:16.\n",
      "loss: 0.0539, acc: 0.9750\n",
      "  Batch 2,200  of  2,463.    Elapsed: 0:11:28.\n",
      "loss: 0.0667, acc: 0.9792\n",
      "  Batch 2,240  of  2,463.    Elapsed: 0:11:40.\n",
      "loss: 0.0492, acc: 0.9750\n",
      "  Batch 2,280  of  2,463.    Elapsed: 0:11:53.\n",
      "loss: 0.0271, acc: 0.9917\n",
      "  Batch 2,320  of  2,463.    Elapsed: 0:12:06.\n",
      "loss: 0.0865, acc: 0.9792\n",
      "  Batch 2,360  of  2,463.    Elapsed: 0:12:19.\n",
      "loss: 0.0280, acc: 0.9958\n",
      "  Batch 2,400  of  2,463.    Elapsed: 0:12:31.\n",
      "loss: 0.0306, acc: 0.9917\n",
      "  Batch 2,440  of  2,463.    Elapsed: 0:12:43.\n",
      "loss: 0.0514, acc: 0.9750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89      2553\n",
      "           1       0.73      0.74      0.73      1232\n",
      "           2       0.81      0.79      0.80      1358\n",
      "\n",
      "    accuracy                           0.83      5143\n",
      "   macro avg       0.81      0.81      0.81      5143\n",
      "weighted avg       0.83      0.83      0.83      5143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_values = []\n",
    "for epoch_i in range(epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    t0 = time.time()\n",
    "#     total_loss=0\n",
    "    model.train()\n",
    "    n_correct, n_total, loss_total = 0, 0, 0\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "\n",
    "        a_input_ids  = batch[0].to(device)\n",
    "        a_input_mask = batch[1].to(device)\n",
    "        b_input_ids  = batch[2].to(device)\n",
    "        b_input_mask = batch[3].to(device)\n",
    "        labels       = batch[4].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        inputs=a_input_ids,a_input_mask,b_input_ids,b_input_mask \n",
    "        predict=model(inputs)\n",
    "        loss=criterion(predict,labels)\n",
    "#         print(predict,labels,loss)\n",
    "#         total_loss+=loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        n_correct += (torch.argmax(predict, -1) == labels).sum().item()\n",
    "        n_total += len(predict)\n",
    "        loss_total += loss.item() * len(predict)\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))        \n",
    "            train_acc = n_correct / n_total\n",
    "            train_loss = loss_total / n_total\n",
    "            loss_plot.append(train_loss)\n",
    "            acc_plot.append(train_acc)\n",
    "            logger.info('loss: {:.4f}, acc: {:.4f}'.format(train_loss, train_acc))   \n",
    "            n_correct, n_total, loss_total = 0, 0, 0\n",
    "            \n",
    "    true_labels,predict_labels=[],[]        \n",
    "    for batch in validation_dataloader:\n",
    "        a_input_ids  = batch[0].to(device)\n",
    "        a_input_mask = batch[1].to(device)\n",
    "        b_input_ids  = batch[2].to(device)\n",
    "        b_input_mask = batch[3].to(device)\n",
    "        labels       = batch[4]\n",
    "        inputs=a_input_ids,a_input_mask,b_input_ids,b_input_mask\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(inputs)        \n",
    "        predict=outputs.detach().cpu().numpy()\n",
    "        predict=np.argmax(predict, axis=1).flatten()\n",
    "        predict_labels.append(predict)\n",
    "        true_labels.append(labels)\n",
    "    true_labels=[y for x in true_labels for y in x]\n",
    "    predict_labels=[y for x in predict_labels for y in x]\n",
    "#     f1_score=f1_score(true_labels,predict_labels,average='weighted')\n",
    "    print(classification_report(true_labels,predict_labels))\n",
    "#     print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5143"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5143"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Training loss and accuracy\") \n",
    "plt.xlabel(\"train epoch\") \n",
    "plt.ylabel(\"acc or loss\") \n",
    "plt.plot(loss_plot, color='firebrick',   label='training loss')\n",
    "plt.plot(acc_plot,  color='darkorange',   label='accuracy')\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
