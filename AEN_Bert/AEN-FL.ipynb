{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import numpy as np\n",
    "data_process=imp.load_source('data_process','../data_process.py')\n",
    "from data_process import get_xml_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents,train_contexts,train_labels=get_xml_data('../SMP2019/SMP2019_ECISA_Train.xml')\n",
    "validation_sents,validation_contexts,validation_labels=get_xml_data('../SMP2019/SMP2019_ECISA_Dev.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/xuke/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel,BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_name='hfl/chinese-bert-wwm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = BertModel.from_pretrained(bert_name, return_dict=False)\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bertTensor(text_list,MAX_LEN = 128):\n",
    "    words_idx = []\n",
    "    for sent in text_list:\n",
    "        encoded_sent = tokenizer.encode(\n",
    "                            sent,                      # Sentence to encode.\n",
    "                            add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                            max_length = MAX_LEN,          # Truncate all sentences.\n",
    "                            #return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                       )\n",
    "        \n",
    "        words_idx.append(encoded_sent)\n",
    "    \n",
    "    words_idx=pad_sequences(words_idx, maxlen=MAX_LEN, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
    "    words_masks=[]\n",
    "    for sent in words_idx:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        words_masks.append(att_mask)\n",
    "        \n",
    "    return torch.tensor(words_idx),torch.tensor(words_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "train_sents,train_sents_masks=get_bertTensor(train_sents)\n",
    "train_contexts,train_contexts_masks=get_bertTensor(train_contexts,MAX_LEN=256)\n",
    "train_labels=torch.tensor(train_labels)\n",
    "\n",
    "validation_sents,validation_sents_masks=get_bertTensor(validation_sents)\n",
    "validation_contexts,validation_contexts_masks=get_bertTensor(validation_contexts,MAX_LEN=256)\n",
    "validation_labels=torch.tensor(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "train_data = TensorDataset(train_sents,train_sents_masks,train_contexts,train_contexts_masks,train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "validation_data = TensorDataset(validation_sents,validation_sents_masks,validation_contexts,\n",
    "                                validation_contexts_masks,validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 AEN_Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers.dynamic_rnn import DynamicLSTM\n",
    "from layers.squeeze_embedding import SqueezeEmbedding\n",
    "from layers.attention import Attention, NoQueryAttention\n",
    "from layers.point_wise_feed_forward import PositionwiseFeedForward\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEN_BERT(nn.Module):\n",
    "    def __init__(self,bert):\n",
    "        super(AEN_BERT, self).__init__()\n",
    "\n",
    "        dropout=0.1\n",
    "        bert_dim=768    \n",
    "        hidden_dim=300\n",
    "        polarities_dim=3\n",
    "        \n",
    "        self.drop_path_prob=0.0\n",
    "        self.bert=bert\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.attn_k = Attention(bert_dim, out_dim=hidden_dim, n_head=8, score_function='mlp', dropout=dropout)\n",
    "        self.attn_q = Attention(bert_dim, out_dim=hidden_dim, n_head=8, score_function='mlp', dropout=dropout)\n",
    "        self.ffn_c = PositionwiseFeedForward(hidden_dim, dropout=dropout)\n",
    "        self.ffn_t = PositionwiseFeedForward(hidden_dim, dropout=dropout)\n",
    "\n",
    "        self.attn_s1 = Attention(hidden_dim, n_head=8, score_function='mlp', dropout=dropout)\n",
    "        self.dense = nn.Linear(hidden_dim*3, polarities_dim)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "#         context, target = inputs[0], inputs[1]\n",
    "        context_len=128\n",
    "        target_len=128\n",
    "        \n",
    "        target,_=bert(a_input_ids, token_type_ids=None, attention_mask=a_input_mask,)\n",
    "        context,_=bert(b_input_ids, token_type_ids=None, attention_mask=b_input_mask,)\n",
    "#         context_len = torch.sum(context != 0, dim=-1)\n",
    "#         target_len = torch.sum(target != 0, dim=-1)\n",
    "#         context = self.squeeze_embedding(context, context_len)\n",
    "#         context, _ = self.bert(context)\n",
    "        context = self.dropout(context)\n",
    "        target = self.dropout(target)\n",
    "\n",
    "        hc, _ = self.attn_k(context, context)\n",
    "        hc = self.ffn_c(hc)\n",
    "#         ht, _ = self.attn_q(context, target)\n",
    "        ht, _ = self.attn_q(target, target)\n",
    "        ht = self.ffn_t(ht)\n",
    "\n",
    "        s1, _ = self.attn_s1(hc, ht)\n",
    "\n",
    "        hc_mean = torch.div(torch.sum(hc, dim=1), context_len)\n",
    "        ht_mean = torch.div(torch.sum(ht, dim=1), target_len)\n",
    "        s1_mean = torch.div(torch.sum(s1, dim=1), context_len)\n",
    "\n",
    "        x = torch.cat((hc_mean, s1_mean, ht_mean), dim=-1)\n",
    "        out=self.dense(x)\n",
    "#         out = torch.argmax(self.softmax(self.dense(x)),dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "from focalloss import FocalLoss\n",
    "from sklearn.metrics import classification_report,f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0, 1\"\n",
    "# model = torch.nn.DataParallel(model, device_ids=[0,2,3]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():     \n",
    "    device = torch.device(\"cuda\")#select gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert.cuda()\n",
    "model=AEN_BERT(bert)\n",
    "model.cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "alpha=torch.tensor([[2.],[1.],[1.]])\n",
    "criterion=FocalLoss(3,alpha,gamma=2)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot,acc_plot=[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuke/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/xuke/temp/Graduation_design/AEN_Bert/focalloss.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  P = F.softmax(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of  2,463.    Elapsed: 0:00:13.\n",
      "loss: 0.4970, acc: 0.5732\n",
      "  Batch    80  of  2,463.    Elapsed: 0:00:25.\n",
      "loss: 0.3340, acc: 0.7042\n",
      "  Batch   120  of  2,463.    Elapsed: 0:00:36.\n",
      "loss: 0.3649, acc: 0.6417\n",
      "  Batch   160  of  2,463.    Elapsed: 0:00:48.\n",
      "loss: 0.4010, acc: 0.6333\n",
      "  Batch   200  of  2,463.    Elapsed: 0:01:01.\n",
      "loss: 0.2970, acc: 0.7000\n",
      "  Batch   240  of  2,463.    Elapsed: 0:01:14.\n",
      "loss: 0.3298, acc: 0.7208\n",
      "  Batch   280  of  2,463.    Elapsed: 0:01:26.\n",
      "loss: 0.3002, acc: 0.7125\n",
      "  Batch   320  of  2,463.    Elapsed: 0:01:38.\n",
      "loss: 0.2997, acc: 0.7750\n",
      "  Batch   360  of  2,463.    Elapsed: 0:01:50.\n",
      "loss: 0.3072, acc: 0.7208\n",
      "  Batch   400  of  2,463.    Elapsed: 0:02:03.\n",
      "loss: 0.2761, acc: 0.7708\n",
      "  Batch   440  of  2,463.    Elapsed: 0:02:15.\n",
      "loss: 0.2863, acc: 0.7542\n",
      "  Batch   480  of  2,463.    Elapsed: 0:02:27.\n",
      "loss: 0.3096, acc: 0.7167\n",
      "  Batch   520  of  2,463.    Elapsed: 0:02:40.\n",
      "loss: 0.2916, acc: 0.7417\n",
      "  Batch   560  of  2,463.    Elapsed: 0:02:52.\n",
      "loss: 0.2665, acc: 0.7708\n",
      "  Batch   600  of  2,463.    Elapsed: 0:03:04.\n",
      "loss: 0.2743, acc: 0.7833\n",
      "  Batch   640  of  2,463.    Elapsed: 0:03:16.\n",
      "loss: 0.2807, acc: 0.7750\n",
      "  Batch   680  of  2,463.    Elapsed: 0:03:28.\n",
      "loss: 0.2487, acc: 0.7833\n",
      "  Batch   720  of  2,463.    Elapsed: 0:03:41.\n",
      "loss: 0.2238, acc: 0.7917\n",
      "  Batch   760  of  2,463.    Elapsed: 0:03:53.\n",
      "loss: 0.2860, acc: 0.7667\n",
      "  Batch   800  of  2,463.    Elapsed: 0:04:05.\n",
      "loss: 0.2486, acc: 0.7542\n",
      "  Batch   840  of  2,463.    Elapsed: 0:04:18.\n",
      "loss: 0.2052, acc: 0.8000\n",
      "  Batch   880  of  2,463.    Elapsed: 0:04:30.\n",
      "loss: 0.1977, acc: 0.7750\n",
      "  Batch   920  of  2,463.    Elapsed: 0:04:42.\n",
      "loss: 0.2524, acc: 0.7708\n",
      "  Batch   960  of  2,463.    Elapsed: 0:04:54.\n",
      "loss: 0.2631, acc: 0.7667\n",
      "  Batch 1,000  of  2,463.    Elapsed: 0:05:06.\n",
      "loss: 0.2281, acc: 0.7792\n",
      "  Batch 1,040  of  2,463.    Elapsed: 0:05:18.\n",
      "loss: 0.2548, acc: 0.7875\n",
      "  Batch 1,080  of  2,463.    Elapsed: 0:05:30.\n",
      "loss: 0.2193, acc: 0.8083\n",
      "  Batch 1,120  of  2,463.    Elapsed: 0:05:42.\n",
      "loss: 0.2307, acc: 0.8083\n",
      "  Batch 1,160  of  2,463.    Elapsed: 0:05:54.\n",
      "loss: 0.2025, acc: 0.8250\n",
      "  Batch 1,200  of  2,463.    Elapsed: 0:06:06.\n",
      "loss: 0.2630, acc: 0.7875\n",
      "  Batch 1,240  of  2,463.    Elapsed: 0:06:19.\n",
      "loss: 0.2217, acc: 0.7875\n",
      "  Batch 1,280  of  2,463.    Elapsed: 0:06:31.\n",
      "loss: 0.2502, acc: 0.7708\n",
      "  Batch 1,320  of  2,463.    Elapsed: 0:06:43.\n",
      "loss: 0.1877, acc: 0.8250\n",
      "  Batch 1,360  of  2,463.    Elapsed: 0:06:55.\n",
      "loss: 0.2594, acc: 0.7792\n",
      "  Batch 1,400  of  2,463.    Elapsed: 0:07:07.\n",
      "loss: 0.2135, acc: 0.8042\n",
      "  Batch 1,440  of  2,463.    Elapsed: 0:07:20.\n",
      "loss: 0.2299, acc: 0.7833\n",
      "  Batch 1,480  of  2,463.    Elapsed: 0:07:32.\n",
      "loss: 0.2099, acc: 0.7583\n",
      "  Batch 1,520  of  2,463.    Elapsed: 0:07:44.\n",
      "loss: 0.2781, acc: 0.7417\n",
      "  Batch 1,560  of  2,463.    Elapsed: 0:07:57.\n",
      "loss: 0.2025, acc: 0.8083\n",
      "  Batch 1,600  of  2,463.    Elapsed: 0:08:10.\n",
      "loss: 0.2231, acc: 0.8000\n",
      "  Batch 1,640  of  2,463.    Elapsed: 0:08:23.\n",
      "loss: 0.2161, acc: 0.7792\n",
      "  Batch 1,680  of  2,463.    Elapsed: 0:08:36.\n",
      "loss: 0.2136, acc: 0.8000\n",
      "  Batch 1,720  of  2,463.    Elapsed: 0:08:49.\n",
      "loss: 0.1497, acc: 0.8292\n",
      "  Batch 1,760  of  2,463.    Elapsed: 0:09:02.\n",
      "loss: 0.3073, acc: 0.7917\n",
      "  Batch 1,800  of  2,463.    Elapsed: 0:09:15.\n",
      "loss: 0.1749, acc: 0.8500\n",
      "  Batch 1,840  of  2,463.    Elapsed: 0:09:28.\n",
      "loss: 0.2348, acc: 0.7917\n",
      "  Batch 1,880  of  2,463.    Elapsed: 0:09:40.\n",
      "loss: 0.1979, acc: 0.8333\n",
      "  Batch 1,920  of  2,463.    Elapsed: 0:09:53.\n",
      "loss: 0.2071, acc: 0.7667\n",
      "  Batch 1,960  of  2,463.    Elapsed: 0:10:05.\n",
      "loss: 0.2464, acc: 0.7917\n",
      "  Batch 2,000  of  2,463.    Elapsed: 0:10:17.\n",
      "loss: 0.2103, acc: 0.7833\n",
      "  Batch 2,040  of  2,463.    Elapsed: 0:10:29.\n",
      "loss: 0.2010, acc: 0.8042\n",
      "  Batch 2,080  of  2,463.    Elapsed: 0:10:41.\n",
      "loss: 0.1583, acc: 0.8417\n",
      "  Batch 2,120  of  2,463.    Elapsed: 0:10:53.\n",
      "loss: 0.1971, acc: 0.8333\n",
      "  Batch 2,160  of  2,463.    Elapsed: 0:11:06.\n",
      "loss: 0.1577, acc: 0.8333\n",
      "  Batch 2,200  of  2,463.    Elapsed: 0:11:18.\n",
      "loss: 0.2365, acc: 0.8042\n",
      "  Batch 2,240  of  2,463.    Elapsed: 0:11:30.\n",
      "loss: 0.2251, acc: 0.7958\n",
      "  Batch 2,280  of  2,463.    Elapsed: 0:11:42.\n",
      "loss: 0.1602, acc: 0.8667\n",
      "  Batch 2,320  of  2,463.    Elapsed: 0:11:54.\n",
      "loss: 0.1620, acc: 0.8250\n",
      "  Batch 2,360  of  2,463.    Elapsed: 0:12:06.\n",
      "loss: 0.2156, acc: 0.8375\n",
      "  Batch 2,400  of  2,463.    Elapsed: 0:12:18.\n",
      "loss: 0.2681, acc: 0.7625\n",
      "  Batch 2,440  of  2,463.    Elapsed: 0:12:30.\n",
      "loss: 0.2634, acc: 0.7708\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      2553\n",
      "           1       0.73      0.68      0.70      1232\n",
      "           2       0.84      0.70      0.76      1358\n",
      "\n",
      "    accuracy                           0.82      5143\n",
      "   macro avg       0.80      0.77      0.78      5143\n",
      "weighted avg       0.81      0.82      0.81      5143\n",
      "\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  2,463.    Elapsed: 0:00:13.\n",
      "loss: 0.1358, acc: 0.8943\n",
      "  Batch    80  of  2,463.    Elapsed: 0:00:25.\n",
      "loss: 0.1102, acc: 0.8750\n",
      "  Batch   120  of  2,463.    Elapsed: 0:00:37.\n",
      "loss: 0.1709, acc: 0.8083\n",
      "  Batch   160  of  2,463.    Elapsed: 0:00:50.\n",
      "loss: 0.1229, acc: 0.8958\n",
      "  Batch   200  of  2,463.    Elapsed: 0:01:02.\n",
      "loss: 0.1133, acc: 0.8833\n",
      "  Batch   240  of  2,463.    Elapsed: 0:01:14.\n",
      "loss: 0.1488, acc: 0.8583\n",
      "  Batch   280  of  2,463.    Elapsed: 0:01:26.\n",
      "loss: 0.1672, acc: 0.8458\n",
      "  Batch   320  of  2,463.    Elapsed: 0:01:38.\n",
      "loss: 0.2115, acc: 0.7875\n",
      "  Batch   360  of  2,463.    Elapsed: 0:01:50.\n",
      "loss: 0.1622, acc: 0.8583\n",
      "  Batch   400  of  2,463.    Elapsed: 0:02:03.\n",
      "loss: 0.1250, acc: 0.8792\n",
      "  Batch   440  of  2,463.    Elapsed: 0:02:16.\n",
      "loss: 0.1274, acc: 0.8875\n",
      "  Batch   480  of  2,463.    Elapsed: 0:02:29.\n",
      "loss: 0.1140, acc: 0.8792\n",
      "  Batch   520  of  2,463.    Elapsed: 0:02:42.\n",
      "loss: 0.1736, acc: 0.8167\n",
      "  Batch   560  of  2,463.    Elapsed: 0:02:54.\n",
      "loss: 0.1008, acc: 0.9042\n",
      "  Batch   600  of  2,463.    Elapsed: 0:03:06.\n",
      "loss: 0.1857, acc: 0.8250\n",
      "  Batch   640  of  2,463.    Elapsed: 0:03:18.\n",
      "loss: 0.1577, acc: 0.8583\n",
      "  Batch   680  of  2,463.    Elapsed: 0:03:30.\n",
      "loss: 0.1390, acc: 0.8542\n",
      "  Batch   720  of  2,463.    Elapsed: 0:03:42.\n",
      "loss: 0.1036, acc: 0.9000\n",
      "  Batch   760  of  2,463.    Elapsed: 0:03:54.\n",
      "loss: 0.1902, acc: 0.7958\n",
      "  Batch   800  of  2,463.    Elapsed: 0:04:07.\n",
      "loss: 0.1394, acc: 0.8542\n",
      "  Batch   840  of  2,463.    Elapsed: 0:04:19.\n",
      "loss: 0.1423, acc: 0.8417\n",
      "  Batch   880  of  2,463.    Elapsed: 0:04:32.\n",
      "loss: 0.1710, acc: 0.8417\n",
      "  Batch   920  of  2,463.    Elapsed: 0:04:44.\n",
      "loss: 0.1399, acc: 0.8458\n",
      "  Batch   960  of  2,463.    Elapsed: 0:04:57.\n",
      "loss: 0.1386, acc: 0.8708\n",
      "  Batch 1,000  of  2,463.    Elapsed: 0:05:09.\n",
      "loss: 0.1448, acc: 0.8542\n",
      "  Batch 1,040  of  2,463.    Elapsed: 0:05:21.\n",
      "loss: 0.1694, acc: 0.8417\n",
      "  Batch 1,080  of  2,463.    Elapsed: 0:05:34.\n",
      "loss: 0.1585, acc: 0.8333\n",
      "  Batch 1,120  of  2,463.    Elapsed: 0:05:46.\n",
      "loss: 0.1435, acc: 0.8417\n",
      "  Batch 1,160  of  2,463.    Elapsed: 0:05:58.\n",
      "loss: 0.2123, acc: 0.7833\n",
      "  Batch 1,200  of  2,463.    Elapsed: 0:06:10.\n",
      "loss: 0.1780, acc: 0.8375\n",
      "  Batch 1,240  of  2,463.    Elapsed: 0:06:22.\n",
      "loss: 0.1509, acc: 0.8542\n",
      "  Batch 1,280  of  2,463.    Elapsed: 0:06:34.\n",
      "loss: 0.0904, acc: 0.9042\n",
      "  Batch 1,320  of  2,463.    Elapsed: 0:06:46.\n",
      "loss: 0.1337, acc: 0.8625\n",
      "  Batch 1,360  of  2,463.    Elapsed: 0:06:58.\n",
      "loss: 0.1363, acc: 0.8833\n",
      "  Batch 1,400  of  2,463.    Elapsed: 0:07:11.\n",
      "loss: 0.1283, acc: 0.8625\n",
      "  Batch 1,440  of  2,463.    Elapsed: 0:07:23.\n",
      "loss: 0.1458, acc: 0.8625\n",
      "  Batch 1,480  of  2,463.    Elapsed: 0:07:35.\n",
      "loss: 0.1395, acc: 0.8250\n",
      "  Batch 1,520  of  2,463.    Elapsed: 0:07:47.\n",
      "loss: 0.1701, acc: 0.8375\n",
      "  Batch 1,560  of  2,463.    Elapsed: 0:07:59.\n",
      "loss: 0.1350, acc: 0.8625\n",
      "  Batch 1,600  of  2,463.    Elapsed: 0:08:12.\n",
      "loss: 0.1224, acc: 0.8625\n",
      "  Batch 1,640  of  2,463.    Elapsed: 0:08:23.\n",
      "loss: 0.1326, acc: 0.8708\n",
      "  Batch 1,680  of  2,463.    Elapsed: 0:08:35.\n",
      "loss: 0.1246, acc: 0.8792\n",
      "  Batch 1,720  of  2,463.    Elapsed: 0:08:48.\n",
      "loss: 0.1976, acc: 0.8458\n",
      "  Batch 1,760  of  2,463.    Elapsed: 0:09:00.\n",
      "loss: 0.1584, acc: 0.8625\n",
      "  Batch 1,800  of  2,463.    Elapsed: 0:09:13.\n",
      "loss: 0.1213, acc: 0.8792\n",
      "  Batch 1,840  of  2,463.    Elapsed: 0:09:26.\n",
      "loss: 0.1314, acc: 0.8750\n",
      "  Batch 1,880  of  2,463.    Elapsed: 0:09:40.\n",
      "loss: 0.0968, acc: 0.8917\n",
      "  Batch 1,920  of  2,463.    Elapsed: 0:09:53.\n",
      "loss: 0.1878, acc: 0.8417\n",
      "  Batch 1,960  of  2,463.    Elapsed: 0:10:06.\n",
      "loss: 0.1323, acc: 0.8625\n",
      "  Batch 2,000  of  2,463.    Elapsed: 0:10:19.\n",
      "loss: 0.1688, acc: 0.8375\n",
      "  Batch 2,040  of  2,463.    Elapsed: 0:10:32.\n",
      "loss: 0.1575, acc: 0.8500\n",
      "  Batch 2,080  of  2,463.    Elapsed: 0:10:45.\n",
      "loss: 0.1468, acc: 0.8667\n",
      "  Batch 2,120  of  2,463.    Elapsed: 0:10:57.\n",
      "loss: 0.1455, acc: 0.8625\n",
      "  Batch 2,160  of  2,463.    Elapsed: 0:11:09.\n",
      "loss: 0.1938, acc: 0.8167\n",
      "  Batch 2,200  of  2,463.    Elapsed: 0:11:22.\n",
      "loss: 0.1931, acc: 0.8292\n",
      "  Batch 2,240  of  2,463.    Elapsed: 0:11:34.\n",
      "loss: 0.1345, acc: 0.8542\n",
      "  Batch 2,280  of  2,463.    Elapsed: 0:11:46.\n",
      "loss: 0.1435, acc: 0.8458\n",
      "  Batch 2,320  of  2,463.    Elapsed: 0:11:58.\n",
      "loss: 0.1751, acc: 0.8500\n",
      "  Batch 2,360  of  2,463.    Elapsed: 0:12:10.\n",
      "loss: 0.1611, acc: 0.8333\n",
      "  Batch 2,400  of  2,463.    Elapsed: 0:12:22.\n",
      "loss: 0.1605, acc: 0.8250\n",
      "  Batch 2,440  of  2,463.    Elapsed: 0:12:35.\n",
      "loss: 0.1268, acc: 0.8667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90      2553\n",
      "           1       0.75      0.69      0.72      1232\n",
      "           2       0.82      0.79      0.80      1358\n",
      "\n",
      "    accuracy                           0.83      5143\n",
      "   macro avg       0.81      0.80      0.81      5143\n",
      "weighted avg       0.83      0.83      0.83      5143\n",
      "\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  2,463.    Elapsed: 0:00:13.\n",
      "loss: 0.0842, acc: 0.9146\n",
      "  Batch    80  of  2,463.    Elapsed: 0:00:25.\n",
      "loss: 0.0662, acc: 0.9083\n",
      "  Batch   120  of  2,463.    Elapsed: 0:00:37.\n",
      "loss: 0.0817, acc: 0.9250\n",
      "  Batch   160  of  2,463.    Elapsed: 0:00:50.\n",
      "loss: 0.0720, acc: 0.9250\n",
      "  Batch   200  of  2,463.    Elapsed: 0:01:03.\n",
      "loss: 0.0611, acc: 0.9208\n",
      "  Batch   240  of  2,463.    Elapsed: 0:01:15.\n",
      "loss: 0.0927, acc: 0.9250\n",
      "  Batch   280  of  2,463.    Elapsed: 0:01:27.\n",
      "loss: 0.1015, acc: 0.9167\n",
      "  Batch   320  of  2,463.    Elapsed: 0:01:39.\n",
      "loss: 0.0798, acc: 0.9167\n",
      "  Batch   360  of  2,463.    Elapsed: 0:01:51.\n",
      "loss: 0.0662, acc: 0.9167\n",
      "  Batch   400  of  2,463.    Elapsed: 0:02:04.\n",
      "loss: 0.0924, acc: 0.9042\n",
      "  Batch   440  of  2,463.    Elapsed: 0:02:16.\n",
      "loss: 0.0923, acc: 0.8792\n",
      "  Batch   480  of  2,463.    Elapsed: 0:02:28.\n",
      "loss: 0.0707, acc: 0.9250\n",
      "  Batch   520  of  2,463.    Elapsed: 0:02:40.\n",
      "loss: 0.0905, acc: 0.9208\n",
      "  Batch   560  of  2,463.    Elapsed: 0:02:52.\n",
      "loss: 0.0603, acc: 0.9292\n",
      "  Batch   600  of  2,463.    Elapsed: 0:03:05.\n",
      "loss: 0.0813, acc: 0.9083\n",
      "  Batch   640  of  2,463.    Elapsed: 0:03:18.\n",
      "loss: 0.1076, acc: 0.9042\n",
      "  Batch   680  of  2,463.    Elapsed: 0:03:31.\n",
      "loss: 0.0825, acc: 0.9333\n",
      "  Batch   720  of  2,463.    Elapsed: 0:03:43.\n",
      "loss: 0.0836, acc: 0.9042\n",
      "  Batch   760  of  2,463.    Elapsed: 0:03:55.\n",
      "loss: 0.0964, acc: 0.8917\n",
      "  Batch   800  of  2,463.    Elapsed: 0:04:08.\n",
      "loss: 0.0762, acc: 0.9333\n",
      "  Batch   840  of  2,463.    Elapsed: 0:04:20.\n",
      "loss: 0.0886, acc: 0.9250\n",
      "  Batch   880  of  2,463.    Elapsed: 0:04:32.\n",
      "loss: 0.1025, acc: 0.8708\n",
      "  Batch   920  of  2,463.    Elapsed: 0:04:44.\n",
      "loss: 0.1041, acc: 0.8917\n",
      "  Batch   960  of  2,463.    Elapsed: 0:04:57.\n",
      "loss: 0.0799, acc: 0.9167\n",
      "  Batch 1,000  of  2,463.    Elapsed: 0:05:09.\n",
      "loss: 0.0618, acc: 0.9250\n",
      "  Batch 1,040  of  2,463.    Elapsed: 0:05:21.\n",
      "loss: 0.0766, acc: 0.9250\n",
      "  Batch 1,080  of  2,463.    Elapsed: 0:05:34.\n",
      "loss: 0.0799, acc: 0.9167\n",
      "  Batch 1,120  of  2,463.    Elapsed: 0:05:46.\n",
      "loss: 0.0874, acc: 0.9167\n",
      "  Batch 1,160  of  2,463.    Elapsed: 0:05:59.\n",
      "loss: 0.1005, acc: 0.9167\n",
      "  Batch 1,200  of  2,463.    Elapsed: 0:06:11.\n",
      "loss: 0.0701, acc: 0.9292\n",
      "  Batch 1,240  of  2,463.    Elapsed: 0:06:23.\n",
      "loss: 0.0762, acc: 0.9125\n",
      "  Batch 1,280  of  2,463.    Elapsed: 0:06:35.\n",
      "loss: 0.0888, acc: 0.9042\n",
      "  Batch 1,320  of  2,463.    Elapsed: 0:06:48.\n",
      "loss: 0.0962, acc: 0.9000\n",
      "  Batch 1,360  of  2,463.    Elapsed: 0:07:00.\n",
      "loss: 0.1233, acc: 0.8542\n",
      "  Batch 1,400  of  2,463.    Elapsed: 0:07:12.\n",
      "loss: 0.0895, acc: 0.9042\n",
      "  Batch 1,440  of  2,463.    Elapsed: 0:07:24.\n",
      "loss: 0.0799, acc: 0.9333\n",
      "  Batch 1,480  of  2,463.    Elapsed: 0:07:36.\n",
      "loss: 0.0866, acc: 0.8958\n",
      "  Batch 1,520  of  2,463.    Elapsed: 0:07:48.\n",
      "loss: 0.0863, acc: 0.9083\n",
      "  Batch 1,560  of  2,463.    Elapsed: 0:08:00.\n",
      "loss: 0.0906, acc: 0.8792\n",
      "  Batch 1,600  of  2,463.    Elapsed: 0:08:12.\n",
      "loss: 0.0926, acc: 0.9125\n",
      "  Batch 1,640  of  2,463.    Elapsed: 0:08:25.\n",
      "loss: 0.0828, acc: 0.9125\n",
      "  Batch 1,680  of  2,463.    Elapsed: 0:08:37.\n",
      "loss: 0.0936, acc: 0.9000\n",
      "  Batch 1,720  of  2,463.    Elapsed: 0:08:49.\n",
      "loss: 0.0805, acc: 0.9167\n",
      "  Batch 1,760  of  2,463.    Elapsed: 0:09:01.\n",
      "loss: 0.0818, acc: 0.9250\n",
      "  Batch 1,800  of  2,463.    Elapsed: 0:09:13.\n",
      "loss: 0.0914, acc: 0.9292\n",
      "  Batch 1,840  of  2,463.    Elapsed: 0:09:25.\n",
      "loss: 0.1118, acc: 0.8833\n",
      "  Batch 1,880  of  2,463.    Elapsed: 0:09:37.\n",
      "loss: 0.1057, acc: 0.8833\n",
      "  Batch 1,920  of  2,463.    Elapsed: 0:09:50.\n",
      "loss: 0.0978, acc: 0.9083\n",
      "  Batch 1,960  of  2,463.    Elapsed: 0:10:02.\n",
      "loss: 0.0693, acc: 0.9250\n",
      "  Batch 2,000  of  2,463.    Elapsed: 0:10:15.\n",
      "loss: 0.1282, acc: 0.8875\n",
      "  Batch 2,040  of  2,463.    Elapsed: 0:10:29.\n",
      "loss: 0.0844, acc: 0.9125\n",
      "  Batch 2,080  of  2,463.    Elapsed: 0:10:43.\n",
      "loss: 0.0495, acc: 0.9500\n",
      "  Batch 2,120  of  2,463.    Elapsed: 0:10:56.\n",
      "loss: 0.1032, acc: 0.8708\n",
      "  Batch 2,160  of  2,463.    Elapsed: 0:11:09.\n",
      "loss: 0.0711, acc: 0.9375\n",
      "  Batch 2,200  of  2,463.    Elapsed: 0:11:22.\n",
      "loss: 0.0836, acc: 0.8792\n",
      "  Batch 2,240  of  2,463.    Elapsed: 0:11:34.\n",
      "loss: 0.0754, acc: 0.9042\n",
      "  Batch 2,280  of  2,463.    Elapsed: 0:11:46.\n",
      "loss: 0.1506, acc: 0.8292\n",
      "  Batch 2,320  of  2,463.    Elapsed: 0:11:59.\n",
      "loss: 0.0944, acc: 0.9042\n",
      "  Batch 2,360  of  2,463.    Elapsed: 0:12:11.\n",
      "loss: 0.1139, acc: 0.8875\n",
      "  Batch 2,400  of  2,463.    Elapsed: 0:12:23.\n",
      "loss: 0.0836, acc: 0.8958\n",
      "  Batch 2,440  of  2,463.    Elapsed: 0:12:36.\n",
      "loss: 0.0864, acc: 0.8958\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90      2553\n",
      "           1       0.80      0.63      0.70      1232\n",
      "           2       0.80      0.82      0.81      1358\n",
      "\n",
      "    accuracy                           0.83      5143\n",
      "   macro avg       0.82      0.80      0.80      5143\n",
      "weighted avg       0.83      0.83      0.83      5143\n",
      "\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of  2,463.    Elapsed: 0:00:12.\n",
      "loss: 0.0458, acc: 0.9472\n",
      "  Batch    80  of  2,463.    Elapsed: 0:00:25.\n",
      "loss: 0.0340, acc: 0.9583\n",
      "  Batch   120  of  2,463.    Elapsed: 0:00:37.\n",
      "loss: 0.0430, acc: 0.9375\n",
      "  Batch   160  of  2,463.    Elapsed: 0:00:49.\n",
      "loss: 0.0386, acc: 0.9500\n",
      "  Batch   200  of  2,463.    Elapsed: 0:01:01.\n",
      "loss: 0.0234, acc: 0.9667\n",
      "  Batch   240  of  2,463.    Elapsed: 0:01:13.\n",
      "loss: 0.0514, acc: 0.9667\n",
      "  Batch   280  of  2,463.    Elapsed: 0:01:26.\n",
      "loss: 0.0479, acc: 0.9417\n",
      "  Batch   320  of  2,463.    Elapsed: 0:01:38.\n",
      "loss: 0.0339, acc: 0.9625\n",
      "  Batch   360  of  2,463.    Elapsed: 0:01:51.\n",
      "loss: 0.0335, acc: 0.9708\n",
      "  Batch   400  of  2,463.    Elapsed: 0:02:03.\n",
      "loss: 0.0738, acc: 0.9375\n",
      "  Batch   440  of  2,463.    Elapsed: 0:02:15.\n",
      "loss: 0.0553, acc: 0.9417\n",
      "  Batch   480  of  2,463.    Elapsed: 0:02:27.\n",
      "loss: 0.0648, acc: 0.9208\n",
      "  Batch   520  of  2,463.    Elapsed: 0:02:39.\n",
      "loss: 0.0338, acc: 0.9667\n",
      "  Batch   560  of  2,463.    Elapsed: 0:02:51.\n",
      "loss: 0.0399, acc: 0.9625\n",
      "  Batch   600  of  2,463.    Elapsed: 0:03:04.\n",
      "loss: 0.0564, acc: 0.9417\n",
      "  Batch   640  of  2,463.    Elapsed: 0:03:16.\n",
      "loss: 0.0235, acc: 0.9667\n",
      "  Batch   680  of  2,463.    Elapsed: 0:03:28.\n",
      "loss: 0.0333, acc: 0.9583\n",
      "  Batch   720  of  2,463.    Elapsed: 0:03:41.\n",
      "loss: 0.0386, acc: 0.9625\n",
      "  Batch   760  of  2,463.    Elapsed: 0:03:54.\n",
      "loss: 0.0782, acc: 0.9458\n",
      "  Batch   800  of  2,463.    Elapsed: 0:04:07.\n",
      "loss: 0.0414, acc: 0.9375\n",
      "  Batch   840  of  2,463.    Elapsed: 0:04:19.\n",
      "loss: 0.0402, acc: 0.9458\n",
      "  Batch   880  of  2,463.    Elapsed: 0:04:31.\n",
      "loss: 0.0408, acc: 0.9333\n",
      "  Batch   920  of  2,463.    Elapsed: 0:04:44.\n",
      "loss: 0.0783, acc: 0.9125\n",
      "  Batch   960  of  2,463.    Elapsed: 0:04:56.\n",
      "loss: 0.0656, acc: 0.9167\n",
      "  Batch 1,000  of  2,463.    Elapsed: 0:05:08.\n",
      "loss: 0.0387, acc: 0.9625\n",
      "  Batch 1,040  of  2,463.    Elapsed: 0:05:20.\n",
      "loss: 0.0379, acc: 0.9583\n",
      "  Batch 1,080  of  2,463.    Elapsed: 0:05:32.\n",
      "loss: 0.0331, acc: 0.9625\n",
      "  Batch 1,120  of  2,463.    Elapsed: 0:05:44.\n",
      "loss: 0.0572, acc: 0.9333\n",
      "  Batch 1,160  of  2,463.    Elapsed: 0:05:57.\n",
      "loss: 0.0437, acc: 0.9458\n",
      "  Batch 1,200  of  2,463.    Elapsed: 0:06:10.\n",
      "loss: 0.0363, acc: 0.9542\n",
      "  Batch 1,240  of  2,463.    Elapsed: 0:06:22.\n",
      "loss: 0.0470, acc: 0.9458\n",
      "  Batch 1,280  of  2,463.    Elapsed: 0:06:34.\n",
      "loss: 0.0681, acc: 0.9458\n",
      "  Batch 1,320  of  2,463.    Elapsed: 0:06:47.\n",
      "loss: 0.0610, acc: 0.9458\n",
      "  Batch 1,360  of  2,463.    Elapsed: 0:06:59.\n",
      "loss: 0.0633, acc: 0.9250\n",
      "  Batch 1,400  of  2,463.    Elapsed: 0:07:11.\n",
      "loss: 0.0524, acc: 0.9500\n",
      "  Batch 1,440  of  2,463.    Elapsed: 0:07:24.\n",
      "loss: 0.0570, acc: 0.9292\n",
      "  Batch 1,480  of  2,463.    Elapsed: 0:07:36.\n",
      "loss: 0.0377, acc: 0.9500\n",
      "  Batch 1,520  of  2,463.    Elapsed: 0:07:48.\n",
      "loss: 0.0687, acc: 0.9333\n",
      "  Batch 1,560  of  2,463.    Elapsed: 0:08:00.\n",
      "loss: 0.0647, acc: 0.9417\n",
      "  Batch 1,600  of  2,463.    Elapsed: 0:08:12.\n",
      "loss: 0.0605, acc: 0.9250\n",
      "  Batch 1,640  of  2,463.    Elapsed: 0:08:24.\n",
      "loss: 0.0622, acc: 0.9292\n",
      "  Batch 1,680  of  2,463.    Elapsed: 0:08:36.\n",
      "loss: 0.0514, acc: 0.9333\n",
      "  Batch 1,720  of  2,463.    Elapsed: 0:08:49.\n",
      "loss: 0.0440, acc: 0.9458\n",
      "  Batch 1,760  of  2,463.    Elapsed: 0:09:01.\n",
      "loss: 0.0425, acc: 0.9667\n",
      "  Batch 1,800  of  2,463.    Elapsed: 0:09:13.\n",
      "loss: 0.0494, acc: 0.9250\n",
      "  Batch 1,840  of  2,463.    Elapsed: 0:09:25.\n",
      "loss: 0.0758, acc: 0.9375\n",
      "  Batch 1,880  of  2,463.    Elapsed: 0:09:37.\n",
      "loss: 0.0623, acc: 0.9250\n",
      "  Batch 1,920  of  2,463.    Elapsed: 0:09:49.\n",
      "loss: 0.0476, acc: 0.9417\n",
      "  Batch 1,960  of  2,463.    Elapsed: 0:10:01.\n",
      "loss: 0.0420, acc: 0.9500\n",
      "  Batch 2,000  of  2,463.    Elapsed: 0:10:14.\n",
      "loss: 0.1126, acc: 0.9333\n",
      "  Batch 2,040  of  2,463.    Elapsed: 0:10:26.\n",
      "loss: 0.1024, acc: 0.9208\n",
      "  Batch 2,080  of  2,463.    Elapsed: 0:10:39.\n",
      "loss: 0.0637, acc: 0.9375\n",
      "  Batch 2,120  of  2,463.    Elapsed: 0:10:53.\n",
      "loss: 0.0662, acc: 0.9333\n",
      "  Batch 2,160  of  2,463.    Elapsed: 0:11:07.\n",
      "loss: 0.0745, acc: 0.9208\n",
      "  Batch 2,200  of  2,463.    Elapsed: 0:11:20.\n",
      "loss: 0.0634, acc: 0.9417\n",
      "  Batch 2,240  of  2,463.    Elapsed: 0:11:33.\n",
      "loss: 0.0715, acc: 0.9125\n",
      "  Batch 2,280  of  2,463.    Elapsed: 0:11:46.\n",
      "loss: 0.0745, acc: 0.9083\n",
      "  Batch 2,320  of  2,463.    Elapsed: 0:11:58.\n",
      "loss: 0.0645, acc: 0.9292\n",
      "  Batch 2,360  of  2,463.    Elapsed: 0:12:10.\n",
      "loss: 0.0509, acc: 0.9417\n",
      "  Batch 2,400  of  2,463.    Elapsed: 0:12:22.\n",
      "loss: 0.0451, acc: 0.9375\n",
      "  Batch 2,440  of  2,463.    Elapsed: 0:12:34.\n",
      "loss: 0.0569, acc: 0.9208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87      2553\n",
      "           1       0.67      0.74      0.70      1232\n",
      "           2       0.82      0.78      0.80      1358\n",
      "\n",
      "    accuracy                           0.81      5143\n",
      "   macro avg       0.79      0.79      0.79      5143\n",
      "weighted avg       0.82      0.81      0.81      5143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_values = []\n",
    "epochs=4\n",
    "for epoch_i in range(epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    t0 = time.time()\n",
    "#     total_loss=0\n",
    "    model.train()\n",
    "    n_correct, n_total, loss_total = 0, 0, 0\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "\n",
    "        a_input_ids  = batch[0].to(device)\n",
    "        a_input_mask = batch[1].to(device)\n",
    "        b_input_ids  = batch[2].to(device)\n",
    "        b_input_mask = batch[3].to(device)\n",
    "        labels       = batch[4].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        inputs=a_input_ids,a_input_mask,b_input_ids,b_input_mask \n",
    "        predict=model(inputs)\n",
    "        loss=criterion(predict,labels)\n",
    "#         print(predict,labels,loss)\n",
    "#         total_loss+=loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        n_correct += (torch.argmax(predict, -1) == labels).sum().item()\n",
    "        n_total += len(predict)\n",
    "        loss_total += loss.item() * len(predict)\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))        \n",
    "            train_acc = n_correct / n_total\n",
    "            train_loss = loss_total / n_total\n",
    "            loss_plot.append(train_loss)\n",
    "            acc_plot.append(train_acc)\n",
    "            logger.info('loss: {:.4f}, acc: {:.4f}'.format(train_loss, train_acc))   \n",
    "            n_correct, n_total, loss_total = 0, 0, 0\n",
    "            \n",
    "    true_labels,predict_labels=[],[]        \n",
    "    for batch in validation_dataloader:\n",
    "        a_input_ids  = batch[0].to(device)\n",
    "        a_input_mask = batch[1].to(device)\n",
    "        b_input_ids  = batch[2].to(device)\n",
    "        b_input_mask = batch[3].to(device)\n",
    "        labels       = batch[4]\n",
    "        inputs=a_input_ids,a_input_mask,b_input_ids,b_input_mask\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(inputs)        \n",
    "        predict=outputs.detach().cpu().numpy()\n",
    "        predict=np.argmax(predict, axis=1).flatten()\n",
    "        predict_labels.append(predict)\n",
    "        true_labels.append(labels)\n",
    "    true_labels=[y for x in true_labels for y in x]\n",
    "    predict_labels=[y for x in predict_labels for y in x]\n",
    "#     f1_score=f1_score(true_labels,predict_labels,average='weighted')\n",
    "    print(classification_report(true_labels,predict_labels))\n",
    "#     print(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5143"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5143"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.title(\"Training loss and accuracy\") \n",
    "plt.xlabel(\"train epoch\") \n",
    "plt.ylabel(\"acc or loss\") \n",
    "plt.plot(loss_plot, color='firebrick',   label='training loss')\n",
    "plt.plot(acc_plot,  color='darkorange',   label='accuracy')\n",
    "plt.legend() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
